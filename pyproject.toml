[project]
name = "llm-inference-lab"
version = "0.1.0"
description = "A hands-on journey from CPU baseline to optimized CUDA kernels."
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "torch>=2.9.1",
    "transformers>=4.57.3",
    "accelerate>=1.12.0",
    "numpy>=2.0.0",
]

[dependency-groups]
dev = [
    "ruff>=0.14.9",
]

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
# Enable Pyflakes (F), pycodestyle (E, W), and isort (I)
select = ["F", "E", "W", "I"]
ignore = []
